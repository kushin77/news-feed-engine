"""
Elite AI Integration Tests - News Feed Engine
Comprehensive test suite validating all Elite AI modules
"""

import asyncio
import pytest
from datetime import datetime, timezone, timedelta
from unittest.mock import patch


def utc_now():
    """Return timezone-aware UTC datetime."""
    return datetime.now(timezone.utc)


# ============================================================================
# Test Fixtures
# ============================================================================


@pytest.fixture
def sample_content():
    """Sample content for testing"""
    return {
        "id": "test-content-001",
        "title": "AI Breakthrough: New Algorithm Achieves Human-Level Performance",
        "summary": "Researchers have developed a new AI algorithm that demonstrates unprecedented capabilities in reasoning and problem-solving.",
        "category": "technology",
        "tags": ["ai", "machine-learning", "breakthrough", "research"],
        "source_urls": ["https://example.com/ai-news"],
        "created_at": utc_now().isoformat(),
    }


@pytest.fixture
def mock_settings():
    """Mock settings for testing"""
    with patch("processor.config.settings") as mock:
        mock.ANTHROPIC_API_KEY = "test-api-key"
        mock.CLAUDE_MODEL = "claude-3-5-sonnet-20241022"
        mock.ELEVENLABS_API_KEY = "test-elevenlabs-key"
        mock.DID_API_KEY = "test-did-key"
        mock.ENVIRONMENT = "test"
        mock.KAFKA_BOOTSTRAP_SERVERS = "127.0.0.1:9092"
        mock.PROMETHEUS_PORT = 9090
        yield mock


# ============================================================================
# PredictiveContentEngine Tests
# ============================================================================


class TestPredictiveEngine:
    """Tests for the Predictive Content Engine"""

    def test_trend_forecaster_initialization(self):
        """Test TrendForecaster can be initialized"""
        from processor.predictive_engine import TrendForecaster

        forecaster = TrendForecaster()
        assert forecaster is not None
        assert len(forecaster.trend_sources) > 0

    def test_virality_model_scoring(self):
        """Test ViralityModel scoring algorithm"""
        from processor.predictive_engine import ViralityModel

        model = ViralityModel()
        score = model.score({"title": "Test Content", "category": "tech"})
        assert 0.0 <= score <= 1.0

    def test_audience_matcher(self):
        """Test AudienceMatcher segment matching"""
        from processor.predictive_engine import AudienceMatcher

        matcher = AudienceMatcher()
        segments = matcher.match("AI technology startup innovation")
        assert isinstance(segments, list)
        assert len(segments) > 0

    def test_predictive_engine_initialization(self):
        """Test PredictiveContentEngine initialization"""
        from processor.predictive_engine import PredictiveContentEngine

        engine = PredictiveContentEngine()
        assert engine.trend_forecaster is not None
        assert engine.virality_predictor is not None
        assert engine.audience_matcher is not None

    @pytest.mark.asyncio
    async def test_predict_performance(self, sample_content):
        """Test full performance prediction"""
        from processor.predictive_engine import PredictiveContentEngine

        engine = PredictiveContentEngine()
        prediction = await engine.predict_performance(sample_content)

        assert prediction is not None
        assert 0.0 <= prediction.virality_score <= 1.0
        assert len(prediction.optimal_publish_times) > 0
        assert len(prediction.audience_segments) > 0

    def test_trend_surfing_engine_initialization(self):
        """Test TrendSurfingEngine initialization"""
        from processor.predictive_engine import TrendSurfingEngine

        engine = TrendSurfingEngine()
        assert engine.forecaster is not None
        assert engine.monitoring is False


# ============================================================================
# VideoFactory Tests
# ============================================================================


class TestVideoFactory:
    """Tests for the Video Factory module"""

    def test_video_script_generator_initialization(self):
        """Test VideoScriptGenerator can be initialized"""
        from processor.video_factory import VideoScriptGenerator

        generator = VideoScriptGenerator()
        assert generator is not None
        assert len(generator.PLATFORM_CONFIGS) > 0

    def test_platform_configs_exist(self):
        """Test that all expected platform configs exist"""
        from processor.video_factory import VideoScriptGenerator

        generator = VideoScriptGenerator()
        expected_platforms = [
            "youtube",
            "youtube_shorts",
            "tiktok",
            "instagram_reels",
            "linkedin",
            "twitter",
        ]
        for platform in expected_platforms:
            assert platform in generator.PLATFORM_CONFIGS

    def test_elevenlabs_client_initialization(self):
        """Test ElevenLabsClient initialization"""
        from processor.video_factory import ElevenLabsClient

        client = ElevenLabsClient(api_key="test-key")
        assert client is not None
        assert client.api_key == "test-key"

    def test_did_client_initialization(self):
        """Test DIDClient initialization"""
        from processor.video_factory import DIDClient

        client = DIDClient(api_key="test-key")
        assert client is not None
        assert client.api_key == "test-key"

    def test_video_factory_initialization(self):
        """Test VideoFactory full initialization"""
        from processor.video_factory import VideoFactory

        factory = VideoFactory(
            elevenlabs_key="test-elevenlabs-key", did_key="test-did-key"
        )
        assert factory is not None
        assert factory.elevenlabs is not None
        assert factory.did is not None
        assert factory.script_generator is not None

    @pytest.mark.asyncio
    async def test_generate_script(self, sample_content):
        """Test script generation for a platform"""
        from processor.video_factory import VideoScriptGenerator

        generator = VideoScriptGenerator()
        script = await generator.generate_script(sample_content, "youtube")

        assert script is not None
        assert script.title
        assert script.hook
        assert script.estimated_duration > 0

    def test_live_video_generator_initialization(self):
        """Test LiveVideoGenerator initialization"""
        from processor.video_factory import VideoFactory, LiveVideoGenerator

        factory = VideoFactory(elevenlabs_key="test-key", did_key="test-key")
        live_gen = LiveVideoGenerator(factory)
        assert live_gen is not None
        assert live_gen.running is False


# ============================================================================
# AI Agents Tests
# ============================================================================


class TestAIAgents:
    """Tests for the AI Agents module"""

    def test_message_bus_initialization(self):
        """Test AgentMessageBus can be initialized"""
        from processor.ai_agents import AgentMessageBus

        bus = AgentMessageBus()
        assert bus is not None
        assert len(bus.agents) == 0

    def test_agent_states_enum(self):
        """Test AgentState enum values"""
        from processor.ai_agents import AgentState

        assert AgentState.IDLE.value == "idle"
        assert AgentState.THINKING.value == "thinking"
        assert AgentState.EXECUTING.value == "executing"

    def test_message_types_enum(self):
        """Test MessageType enum values"""
        from processor.ai_agents import MessageType

        assert MessageType.TASK.value == "task"
        assert MessageType.HANDOFF.value == "handoff"
        assert MessageType.FEEDBACK.value == "feedback"

    def test_content_item_dataclass(self):
        """Test ContentItem dataclass"""
        from processor.ai_agents import ContentItem

        item = ContentItem(
            id="test-123",
            title="Test Title",
            description="Test Description",
            trend_score=0.85,
            category="technology",
            keywords=["test", "ai"],
            source_urls=["https://example.com"],
            created_at=utc_now(),
        )
        assert item.id == "test-123"
        assert item.trend_score == 0.85
        assert item.curated is False

    def test_analyst_agent_initialization(self):
        """Test AnalystAgent can be initialized without dependencies"""
        from processor.ai_agents import AnalystAgent

        agent = AnalystAgent()
        assert agent is not None
        assert agent.name == "Analyst"

    def test_engagement_agent_initialization(self):
        """Test EngagementAgent can be initialized"""
        from processor.ai_agents import EngagementAgent

        agent = EngagementAgent()
        assert agent is not None
        assert agent.name == "Engager"


# ============================================================================
# Trend Sources Tests
# ============================================================================


class TestTrendSources:
    """Tests for Trend Sources module"""

    def test_trend_aggregator_structure(self):
        """Test trend source module structure"""
        from data.processors import trend_sources

        assert hasattr(trend_sources, "logger")

    def test_module_imports_correctly(self):
        """Test module can be imported"""
        import processor.trend_sources as ts

        assert ts is not None


# ============================================================================
# Analytics Pipeline Tests
# ============================================================================


class TestAnalyticsPipeline:
    """Tests for Analytics Pipeline module"""

    def test_metrics_exporter_initialization(self):
        """Test MetricsExporter can be initialized"""
        from processor.analytics_pipeline import MetricsExporter

        exporter = MetricsExporter(namespace="test")
        assert exporter is not None
        assert exporter.namespace == "test"

    def test_event_types_enum(self):
        """Test EventType enum values"""
        from processor.analytics_pipeline import EventType

        assert EventType.CONTENT_CREATED.value == "content.created"
        assert EventType.VIDEO_PRODUCED.value == "video.produced"
        assert EventType.PUBLISH_SUCCESS.value == "publish.success"

    def test_pipeline_event_dataclass(self):
        """Test PipelineEvent dataclass"""
        from processor.analytics_pipeline import PipelineEvent, EventType

        event = PipelineEvent(
            event_id="evt-001",
            event_type=EventType.CONTENT_CREATED,
            timestamp=utc_now(),
            source="test",
            data={"test": "data"},
        )
        assert event.event_id == "evt-001"
        assert event.event_type == EventType.CONTENT_CREATED

    def test_event_producer_initialization(self):
        """Test EventProducer can be initialized"""
        from processor.analytics_pipeline import EventProducer

        producer = EventProducer()
        assert producer is not None
        assert producer.topic_prefix == "newsfeed"

    def test_analytics_processor_initialization(self):
        """Test AnalyticsProcessor initialization"""
        from processor.analytics_pipeline import AnalyticsProcessor, MetricsExporter

        metrics = MetricsExporter()
        processor = AnalyticsProcessor(metrics)
        assert processor is not None
        assert processor.metrics is not None

    def test_analytics_pipeline_initialization(self):
        """Test AnalyticsPipeline initialization"""
        from processor.analytics_pipeline import AnalyticsPipeline

        pipeline = AnalyticsPipeline()
        assert pipeline is not None
        assert pipeline.producer is not None
        assert pipeline.metrics is not None

    def test_grafana_dashboard_generation(self):
        """Test Grafana dashboard config generation"""
        from processor.analytics_pipeline import generate_grafana_dashboard

        config = generate_grafana_dashboard()
        assert config is not None
        assert "dashboard" in config
        assert "panels" in config["dashboard"]
        assert len(config["dashboard"]["panels"]) > 0


# ============================================================================
# OAuth Manager Tests
# ============================================================================


class TestOAuthManager:
    """Tests for OAuth Manager module"""

    def test_oauth_token_dataclass(self):
        """Test OAuthToken dataclass"""
        from processor.oauth_manager import OAuthToken

        token = OAuthToken(
            access_token="test-token", expires_in=3600, platform="youtube"
        )
        assert token.access_token == "test-token"
        assert token.expires_in == 3600
        assert not token.is_expired

    def test_in_memory_token_storage(self):
        """Test InMemoryTokenStorage"""
        from processor.oauth_manager import InMemoryTokenStorage

        storage = InMemoryTokenStorage()
        assert storage is not None

    @pytest.mark.asyncio
    async def test_token_storage_operations(self):
        """Test token storage save and retrieve"""
        from processor.oauth_manager import InMemoryTokenStorage, OAuthToken

        storage = InMemoryTokenStorage()
        token = OAuthToken(
            access_token="test-token", expires_in=3600, platform="youtube"
        )
        await storage.save_token("user-1", "youtube", token)
        retrieved = await storage.get_token("user-1", "youtube")
        assert retrieved is not None
        assert retrieved.access_token == "test-token"

    def test_encrypted_token_storage(self):
        """Test EncryptedTokenStorage initialization"""
        from processor.oauth_manager import EncryptedTokenStorage

        storage = EncryptedTokenStorage(encryption_key="test-key-32bytes!!")
        assert storage is not None

    def test_oauth_manager_initialization(self):
        """Test OAuthManager initialization"""
        from processor.oauth_manager import OAuthManager

        manager = OAuthManager()
        assert manager is not None
        assert manager.storage is not None


# ============================================================================
# Publishing Orchestrator Tests
# ============================================================================


class TestPublishingOrchestrator:
    """Tests for Publishing Orchestrator module"""

    def test_orchestrator_initialization(self):
        """Test PublishingOrchestrator initialization"""
        from processor.publishing_orchestrator import PublishingOrchestrator

        orchestrator = PublishingOrchestrator()
        assert orchestrator is not None
        assert orchestrator.running is False

    def test_platform_enum(self):
        """Test Platform enum values"""
        from processor.publishing_orchestrator import Platform

        assert Platform.YOUTUBE.value == "youtube"
        assert Platform.TIKTOK.value == "tiktok"
        assert Platform.LINKEDIN.value == "linkedin"

    def test_publish_status_enum(self):
        """Test PublishStatus enum values"""
        from processor.publishing_orchestrator import PublishStatus

        assert PublishStatus.PENDING.value == "pending"
        assert PublishStatus.PUBLISHED.value == "published"
        assert PublishStatus.FAILED.value == "failed"

    def test_scheduled_post_dataclass(self):
        """Test ScheduledPost dataclass"""
        from processor.publishing_orchestrator import (
            ScheduledPost,
            Platform,
            PublishStatus,
        )

        post = ScheduledPost(
            id="post-001",
            content_id="content-001",
            platform=Platform.YOUTUBE,
            scheduled_time=utc_now(),
            content={"title": "Test"},
            media_urls=["https://example.com/video.mp4"],
            caption="Test caption",
            hashtags=["#test"],
        )
        assert post.id == "post-001"
        assert post.status == PublishStatus.SCHEDULED

    def test_rate_limiter_initialization(self):
        """Test RateLimiter initialization"""
        from processor.publishing_orchestrator import RateLimiter

        limiter = RateLimiter(tokens_per_hour=60)
        assert limiter is not None
        assert limiter.tokens_per_hour == 60

    def test_hashtag_optimizer_initialization(self):
        """Test HashtagOptimizer initialization"""
        from processor.publishing_orchestrator import HashtagOptimizer

        optimizer = HashtagOptimizer()
        assert optimizer is not None

    def test_timing_optimizer_initialization(self):
        """Test TimingOptimizer initialization"""
        from processor.publishing_orchestrator import TimingOptimizer

        optimizer = TimingOptimizer()
        assert optimizer is not None
        assert len(optimizer.platform_peaks) > 0

    @pytest.mark.asyncio
    async def test_hashtag_optimization(self, sample_content):
        """Test hashtag optimization for content"""
        from processor.publishing_orchestrator import HashtagOptimizer, Platform

        optimizer = HashtagOptimizer()
        hashtags = await optimizer.optimize_hashtags(
            sample_content, Platform.YOUTUBE, max_hashtags=10
        )
        assert isinstance(hashtags, list)


# ============================================================================
# Media Manager Tests
# ============================================================================


class TestMediaManager:
    """Tests for Media Manager module"""

    def test_asset_type_enum(self):
        """Test AssetType enum values"""
        from processor.media_manager import AssetType

        assert AssetType.IMAGE.value == "image"
        assert AssetType.VIDEO.value == "video"
        assert AssetType.AUDIO.value == "audio"

    def test_media_asset_dataclass(self):
        """Test MediaAsset dataclass"""
        from processor.media_manager import MediaAsset, AssetType, AssetURLs

        urls = AssetURLs(
            original="https://example.com/original.jpg",
            cdn="https://cdn.example.com/image.jpg",
        )
        asset = MediaAsset(
            id="asset-001",
            tenant_id="tenant-001",
            type=AssetType.IMAGE,
            source_platform="upload",
            urls=urls,
            filename="test.jpg",
            file_size=1024,
            mime_type="image/jpeg",
        )
        assert asset.id == "asset-001"
        assert asset.type == AssetType.IMAGE

    def test_media_manager_client_initialization(self):
        """Test MediaManagerClient can be instantiated"""
        from processor.media_manager import MediaManagerClient

        client = MediaManagerClient(
            base_url="https://api.example.com",
            api_key="test-key",
            tenant_id="tenant-001",
        )
        assert client is not None
        assert client.tenant_id == "tenant-001"

    def test_cdn_manager_initialization(self):
        """Test CDNManager initialization"""
        from processor.media_manager import CDNManager

        cdn = CDNManager(cdn_base_url="https://cdn.example.com", cdn_api_key="test-key")
        assert cdn is not None

    def test_media_manager_integration_initialization(self):
        """Test MediaManagerIntegration initialization"""
        from processor.media_manager import MediaManagerIntegration

        integration = MediaManagerIntegration(
            base_url="https://api.example.com",
            api_key="test-key",
            tenant_id="tenant-001",
            cdn_base_url="https://cdn.example.com",
            cdn_api_key="cdn-key",
        )
        assert integration is not None


# ============================================================================
# Full Pipeline Integration Tests
# ============================================================================


class TestFullPipelineIntegration:
    """Integration tests for the complete pipeline"""

    @pytest.mark.asyncio
    async def test_analytics_event_flow(self):
        """Test analytics event creation and processing flow"""
        from processor.analytics_pipeline import (
            EventProducer,
            EventType,
            AnalyticsProcessor,
            MetricsExporter,
        )

        producer = EventProducer()
        await producer.start()

        metrics = MetricsExporter()
        processor = AnalyticsProcessor(metrics)

        # Create and process event
        event = producer.create_event(
            event_type=EventType.CONTENT_CREATED,
            source="test",
            data={"category": "technology", "source": "test"},
        )

        await processor.process_event(event)

        # Verify dashboard data
        dashboard = processor.get_dashboard_data()
        assert "aggregations" in dashboard
        assert "alerts" in dashboard

        await producer.stop()


# ============================================================================
# Performance Tests
# ============================================================================


class TestPerformance:
    """Performance and stress tests"""

    @pytest.mark.asyncio
    async def test_prediction_performance(self, sample_content):
        """Test prediction engine performance"""
        import time
        from processor.predictive_engine import PredictiveContentEngine

        engine = PredictiveContentEngine()

        start_time = time.time()
        for _ in range(10):
            await engine.predict_performance(sample_content)
        elapsed = time.time() - start_time

        # Should complete 10 predictions in under 5 seconds
        assert elapsed < 5.0

    def test_virality_model_batch_scoring(self):
        """Test batch scoring performance"""
        import time
        from processor.predictive_engine import ViralityModel

        model = ViralityModel()
        contents = [{"title": f"Test {i}", "category": "tech"} for i in range(100)]

        start_time = time.time()
        scores = [model.score(c) for c in contents]
        elapsed = time.time() - start_time

        assert len(scores) == 100
        assert elapsed < 1.0  # Should complete in under 1 second


# ============================================================================
# Configuration Tests
# ============================================================================


class TestConfiguration:
    """Tests for configuration module"""

    def test_settings_singleton_exists(self):
        """Test that settings singleton exists"""
        from processor.config import settings

        assert settings is not None

    def test_get_settings_function(self):
        """Test get_settings function"""
        from processor.config import get_settings

        settings = get_settings()
        assert settings is not None

    def test_utc_now_returns_timezone_aware(self):
        """Test utc_now returns timezone-aware datetime"""
        from processor.config import utc_now

        dt = utc_now()
        assert dt.tzinfo is not None

    def test_settings_environment_default(self):
        """Test default environment is development"""
        from processor.config import settings

        assert settings.environment in ["development", "production", "staging", "test"]

    def test_settings_database_defaults(self):
        """Test database settings have defaults"""
        from processor.config import settings

        assert settings.postgres_host is not None
        assert settings.postgres_port == 5432
        assert settings.redis_url is not None


# ============================================================================
# Extended AI Agents Tests
# ============================================================================


class TestAIAgentsExtended:
    """Extended tests for AI agents module"""

    def test_agent_decision_dataclass(self):
        """Test AgentDecision dataclass"""
        from processor.ai_agents import AgentDecision

        decision = AgentDecision(
            decision_id="test-123",
            agent_name="test_agent",
            decision_type="evaluation",
            input_data={"key": "value"},
            reasoning="Test reasoning",
            action="approve",
            confidence=0.85,
        )

        assert decision.decision_id == "test-123"
        assert decision.confidence == 0.85
        assert decision.outcome is None

    def test_agent_message_dataclass(self):
        """Test AgentMessage dataclass"""
        from processor.ai_agents import AgentMessage, MessageType

        message = AgentMessage(
            id="msg-123",
            sender="agent1",
            recipient="agent2",
            message_type=MessageType.TASK,
            payload={"task": "process"},
        )

        assert message.sender == "agent1"
        assert message.message_type == MessageType.TASK
        assert message.priority == 5  # default

    def test_content_curator_agent_type(self):
        """Test ContentCuratorAgent class exists and is properly typed"""
        from processor.ai_agents import ContentCuratorAgent

        # Verify class exists and has expected attributes
        assert ContentCuratorAgent is not None
        assert hasattr(ContentCuratorAgent, "__init__")
        # Agent requires trend_engine parameter - just verify class structure

    def test_video_producer_agent_type(self):
        """Test VideoProducerAgent class exists and is properly typed"""
        from processor.ai_agents import VideoProducerAgent

        # Verify class exists and has expected attributes
        assert VideoProducerAgent is not None
        assert hasattr(VideoProducerAgent, "__init__")
        # Agent requires video_pipeline parameter - just verify class structure

    def test_distributor_agent_type(self):
        """Test DistributorAgent class exists and is properly typed"""
        from processor.ai_agents import DistributorAgent

        # Verify class exists and has expected attributes
        assert DistributorAgent is not None
        assert hasattr(DistributorAgent, "__init__")
        # Agent requires publishing_orchestrator parameter - just verify class structure


# ============================================================================
# Extended Trend Sources Tests
# ============================================================================


class TestTrendSourcesExtended:
    """Extended tests for trend sources module"""

    def test_trend_item_dataclass(self):
        """Test TrendItem dataclass"""
        from processor.trend_sources import TrendItem

        trend = TrendItem(
            id="trend-123",
            name="Test Trend",
            source="test",
            score=0.85,
            volume=10000,
            growth_rate=0.15,  # Required field
        )

        assert trend.name == "Test Trend"
        assert trend.score == 0.85
        assert trend.growth_rate == 0.15

    def test_trend_aggregation_dataclass(self):
        """Test TrendAggregation dataclass"""
        from processor.trend_sources import TrendAggregation

        aggregation = TrendAggregation(
            name="Test Trend",
            normalized_name="test_trend",
            sources=["google", "twitter"],
            combined_score=0.85,
            total_volume=10000,
            avg_growth_rate=0.15,
        )
        assert aggregation is not None
        assert aggregation.combined_score == 0.85
        assert len(aggregation.sources) == 2

    def test_trend_aggregator_initialization(self):
        """Test TrendAggregator initialization"""
        from processor.trend_sources import TrendAggregator

        aggregator = TrendAggregator()
        assert aggregator is not None
        # Check actual methods
        assert hasattr(aggregator, "aggregate_trends")
        assert hasattr(aggregator, "get_top_trends")

    def test_base_trend_source_implementation(self):
        """Test GoogleTrendsSource implementation"""
        from processor.trend_sources import GoogleTrendsSource

        source = GoogleTrendsSource()
        assert source is not None
        assert hasattr(source, "fetch_trends") or hasattr(source, "get_trends")


# ============================================================================
# Extended Analytics Pipeline Tests
# ============================================================================


class TestAnalyticsPipelineExtended:
    """Extended tests for analytics pipeline module"""

    def test_pipeline_event_to_dict(self):
        """Test PipelineEvent to_dict method"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        event = PipelineEvent(
            event_id="evt-123",
            event_type=EventType.CONTENT_CREATED,
            timestamp=utc_now(),
            source="test",
            data={"content_id": "123"},
        )

        event_dict = event.to_dict()
        assert event_dict["event_id"] == "evt-123"
        assert "timestamp" in event_dict

    def test_pipeline_event_to_json(self):
        """Test PipelineEvent to_json method"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now
        import json

        event = PipelineEvent(
            event_id="evt-456",
            event_type=EventType.VIDEO_PRODUCED,
            timestamp=utc_now(),
            source="video_factory",
            data={"video_id": "456"},
        )

        json_str = event.to_json()
        parsed = json.loads(json_str)
        assert parsed["event_id"] == "evt-456"

    def test_create_pipeline_event_from_class(self):
        """Test creating PipelineEvent with factory pattern"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        # Create event directly
        event = PipelineEvent(
            event_id="evt-789",
            event_type=EventType.PUBLISH_SUCCESS,
            timestamp=utc_now(),
            source="orchestrator",
            data={"platform": "youtube", "post_id": "123"},
        )

        assert event is not None
        assert event.event_type == EventType.PUBLISH_SUCCESS
        assert event.source == "orchestrator"


# ============================================================================
# Extended OAuth Manager Tests
# ============================================================================


class TestOAuthManagerExtended:
    """Extended tests for OAuth manager module"""

    def test_oauth_state_dataclass(self):
        """Test OAuthState dataclass"""
        from processor.oauth_manager import OAuthState

        state = OAuthState(
            state="abc123", platform="youtube", redirect_uri="http://127.0.0.1/callback"
        )

        assert state.state == "abc123"
        assert state.platform == "youtube"
        assert not state.is_expired

    def test_oauth_token_expiry_check(self):
        """Test OAuthToken expiry calculation"""
        from processor.oauth_manager import OAuthToken
        from processor.config import utc_now

        # Create token expiring in 10 minutes
        token = OAuthToken(
            access_token="test-token",
            expires_in=600,  # 10 minutes
            created_at=utc_now(),
        )

        assert not token.is_expired

    def test_oauth_token_to_dict(self):
        """Test OAuthToken to_dict method"""
        from processor.oauth_manager import OAuthToken

        token = OAuthToken(
            access_token="test-token",
            token_type="Bearer",
            expires_in=3600,
            platform="youtube",
        )

        token_dict = token.to_dict()
        assert token_dict["access_token"] == "test-token"
        assert token_dict["platform"] == "youtube"


# ============================================================================
# Extended Video Factory Tests
# ============================================================================


class TestVideoFactoryExtended:
    """Extended tests for video factory module"""

    def test_video_script_dataclass(self):
        """Test VideoScript dataclass"""
        from processor.video_factory import VideoScript

        script = VideoScript(
            title="Breaking News Video",
            hook="Breaking news...",
            body="This is the main content of the video.",
            call_to_action="Subscribe for more!",
        )

        assert script.hook == "Breaking news..."
        assert script.title == "Breaking News Video"
        assert script.call_to_action == "Subscribe for more!"

    def test_video_style_enum(self):
        """Test VideoStyle enum"""
        from processor.video_factory import VideoStyle

        # Check enum values exist
        assert hasattr(VideoStyle, "PROFESSIONAL") or len(list(VideoStyle)) > 0

    def test_platform_config_dataclass(self):
        """Test PlatformConfig dataclass"""
        from processor.video_factory import PlatformConfig

        config = PlatformConfig
        assert config is not None


# ============================================================================
# Extended Publishing Orchestrator Tests
# ============================================================================


class TestPublishingOrchestratorExtended:
    """Extended tests for publishing orchestrator module"""

    def test_publish_result_dataclass(self):
        """Test PublishResult dataclass"""
        from processor.publishing_orchestrator import PublishResult, Platform

        result = PublishResult(
            platform=Platform.YOUTUBE,
            success=True,
            post_id="yt-123",
            url="https://youtube.com/watch?v=123",
        )

        assert result.platform == Platform.YOUTUBE
        assert result.success is True
        assert result.post_id == "yt-123"

    def test_timing_optimizer_get_optimal_times(self):
        """Test TimingOptimizer get_optimal_times method"""
        from processor.publishing_orchestrator import TimingOptimizer, Platform

        optimizer = TimingOptimizer()
        # Method requires platform and content arguments
        content = {"title": "Test Video", "type": "video"}
        times = optimizer.get_optimal_times(Platform.YOUTUBE, content)

        assert times is not None
        assert len(times) > 0


# ============================================================================
# E2E Pipeline Integration Tests
# ============================================================================


class TestE2EPipelineFlow:
    """End-to-end tests for the complete pipeline flow"""

    def test_trend_to_video_workflow(self):
        """Test complete workflow from trend detection to video generation"""
        from processor.trend_sources import TrendItem
        from processor.video_factory import VideoScript, VideoScriptGenerator

        # Step 1: Create a trend item (simulating trend detection)
        trend = TrendItem(
            id="trend-e2e-001",
            name="AI Revolution 2024",
            source="google",
            score=0.92,
            volume=150000,
            growth_rate=0.35,
            category="technology",
            description="Latest developments in artificial intelligence",
        )

        assert trend.score > 0.9
        assert trend.growth_rate > 0.3

        # Step 2: Generate a video script from the trend
        generator = VideoScriptGenerator()
        assert generator is not None

        # Step 3: Create a script based on trend
        script = VideoScript(
            title=f"Breaking: {trend.name}",
            hook=f"The {trend.name} is changing everything!",
            body=trend.description or "AI is transforming every industry.",
            call_to_action="Subscribe for more tech updates!",
        )

        assert script.title == f"Breaking: {trend.name}"
        assert script.hook is not None

    def test_analytics_event_pipeline(self):
        """Test analytics event creation and processing"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        # Create events for different pipeline stages
        events = []

        # Content creation event
        events.append(
            PipelineEvent(
                event_id="evt-e2e-001",
                event_type=EventType.CONTENT_CREATED,
                timestamp=utc_now(),
                source="content_curator",
                data={"content_id": "content-001", "type": "news_article"},
            )
        )

        # Video production event
        events.append(
            PipelineEvent(
                event_id="evt-e2e-002",
                event_type=EventType.VIDEO_PRODUCED,
                timestamp=utc_now(),
                source="video_factory",
                data={"video_id": "video-001", "duration": 60},
            )
        )

        # Publish success event
        events.append(
            PipelineEvent(
                event_id="evt-e2e-003",
                event_type=EventType.PUBLISH_SUCCESS,
                timestamp=utc_now(),
                source="orchestrator",
                data={"platform": "youtube", "post_id": "yt-001"},
            )
        )

        # Verify all events can be serialized
        for event in events:
            event_dict = event.to_dict()
            assert "event_id" in event_dict
            assert "event_type" in event_dict
            assert "timestamp" in event_dict

    def test_oauth_token_lifecycle(self):
        """Test OAuth token creation, storage, and retrieval"""
        from processor.oauth_manager import OAuthToken
        from processor.config import utc_now

        # Create tokens for multiple platforms (just test token creation, not async storage)
        platforms = ["youtube", "instagram", "tiktok", "twitter"]

        tokens = []
        for platform in platforms:
            token = OAuthToken(
                access_token=f"access-token-{platform}",
                token_type="Bearer",
                expires_in=3600,
                platform=platform,
                created_at=utc_now(),
            )
            tokens.append(token)
            assert token.platform == platform
            assert not token.is_expired

        # Verify all tokens created
        assert len(tokens) == 4
        for token in tokens:
            assert token.access_token.startswith("access-token-")

    def test_multi_platform_publishing_setup(self):
        """Test setup for multi-platform publishing"""
        from processor.publishing_orchestrator import (
            PublishingOrchestrator,
            Platform,
            TimingOptimizer,
            HashtagOptimizer,
            RateLimiter,
        )

        # Initialize components
        orchestrator = PublishingOrchestrator()
        timing_optimizer = TimingOptimizer()
        hashtag_optimizer = HashtagOptimizer()
        rate_limiter = RateLimiter()

        # Verify all components initialized
        assert orchestrator is not None
        assert timing_optimizer is not None
        assert hashtag_optimizer is not None
        assert rate_limiter is not None

        # Test timing for all platforms
        content = {"title": "E2E Test Video", "category": "tech"}
        for platform in [Platform.YOUTUBE, Platform.INSTAGRAM_REELS, Platform.TIKTOK]:
            times = timing_optimizer.get_optimal_times(platform, content)
            assert times is not None

    def test_trend_aggregation_workflow(self):
        """Test trend aggregation from multiple sources"""
        from processor.trend_sources import TrendItem, TrendAggregator

        TrendAggregator()

        # Create trends from different sources
        trends = [
            TrendItem(
                id="t-google-001",
                name="AI Assistant",
                source="google",
                score=0.88,
                volume=100000,
                growth_rate=0.25,
            ),
            TrendItem(
                id="t-twitter-001",
                name="AI Assistant",
                source="twitter",
                score=0.82,
                volume=50000,
                growth_rate=0.30,
            ),
            TrendItem(
                id="t-tiktok-001",
                name="AI Assistant Tools",
                source="tiktok",
                score=0.90,
                volume=200000,
                growth_rate=0.40,
            ),
        ]

        # Verify trend creation
        for trend in trends:
            assert trend.source in ["google", "twitter", "tiktok"]
            assert trend.score > 0.8

    def test_media_manager_asset_workflow(self):
        """Test media asset creation and management"""
        from processor.media_manager import MediaAsset, AssetType, AssetURLs

        # Create AssetURLs required by MediaAsset
        video_urls = AssetURLs(
            original="https://storage.example.com/video.mp4",
            cdn="https://cdn.example.com/video.mp4",
            thumbnails={"small": "https://cdn.example.com/thumb_s.jpg"},
            optimized={"720p": "https://cdn.example.com/video_720.mp4"},
            transcoded={"webm": "https://cdn.example.com/video.webm"},
        )

        # Create a proper media asset with all required fields
        asset = MediaAsset(
            id="asset-001",
            tenant_id="tenant-001",
            type=AssetType.VIDEO,
            source_platform="youtube",
            urls=video_urls,
            filename="intro_video.mp4",
            file_size=1024 * 1024 * 10,  # 10MB
            mime_type="video/mp4",
            width=1920,
            height=1080,
            duration=60.0,
        )

        # Verify asset creation
        assert asset.id == "asset-001"
        assert asset.filename == "intro_video.mp4"
        assert asset.file_size > 0
        assert asset.type == AssetType.VIDEO


# ============================================================================
# Performance Benchmark Tests
# ============================================================================


class TestPerformanceBenchmarks:
    """Performance benchmark tests"""

    def test_trend_item_creation_performance(self):
        """Benchmark TrendItem creation"""
        from processor.trend_sources import TrendItem
        import time

        start = time.perf_counter()
        trends = []
        for i in range(1000):
            trends.append(
                TrendItem(
                    id=f"trend-{i}",
                    name=f"Test Trend {i}",
                    source="benchmark",
                    score=0.5 + (i % 50) / 100,
                    volume=i * 100,
                    growth_rate=0.1 + (i % 20) / 100,
                )
            )
        elapsed = time.perf_counter() - start

        assert len(trends) == 1000
        assert elapsed < 1.0  # Should complete in under 1 second

    def test_pipeline_event_creation_performance(self):
        """Benchmark PipelineEvent creation and serialization"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now
        import time

        start = time.perf_counter()
        events = []
        for i in range(1000):
            event = PipelineEvent(
                event_id=f"evt-{i}",
                event_type=EventType.CONTENT_CREATED,
                timestamp=utc_now(),
                source="benchmark",
                data={"index": i},
            )
            events.append(event.to_dict())
        elapsed = time.perf_counter() - start

        assert len(events) == 1000
        assert elapsed < 2.0  # Should complete in under 2 seconds

    def test_hashtag_optimization_performance(self):
        """Benchmark hashtag optimization - tests HashtagOptimizer initialization"""
        from processor.publishing_orchestrator import HashtagOptimizer
        import time

        start = time.perf_counter()
        optimizers = []
        for i in range(100):
            # Create optimizer instances (optimize_hashtags is async, test init instead)
            optimizer = HashtagOptimizer()
            optimizers.append(optimizer)
        elapsed = time.perf_counter() - start

        assert len(optimizers) == 100
        assert elapsed < 2.0  # Should complete in under 2 seconds

    def test_video_script_generation_performance(self):
        """Benchmark video script creation"""
        from processor.video_factory import VideoScript
        import time

        start = time.perf_counter()
        scripts = []
        for i in range(500):
            scripts.append(
                VideoScript(
                    title=f"Video Title {i}",
                    hook=f"Amazing hook for video {i}",
                    body=f"This is the main content of video {i}. " * 10,
                    call_to_action=f"Subscribe now! {i}",
                )
            )
        elapsed = time.perf_counter() - start

        assert len(scripts) == 500
        assert elapsed < 1.0  # Should complete in under 1 second


# ============================================================================
# Error Handling Tests
# ============================================================================


class TestErrorHandling:
    """Tests for error handling and edge cases"""

    def test_invalid_trend_score_handling(self):
        """Test handling of edge case trend scores"""
        from processor.trend_sources import TrendItem

        # Test with boundary values
        trend_zero = TrendItem(
            id="t-zero",
            name="Zero Score Trend",
            source="test",
            score=0.0,
            volume=0,
            growth_rate=0.0,
        )
        assert trend_zero.score == 0.0

        trend_max = TrendItem(
            id="t-max",
            name="Max Score Trend",
            source="test",
            score=1.0,
            volume=999999999,
            growth_rate=1.0,
        )
        assert trend_max.score == 1.0

    def test_empty_content_handling(self):
        """Test handling of empty content"""
        from processor.video_factory import VideoScript

        # Empty strings should be allowed
        script = VideoScript(title="", hook="", body="", call_to_action="")
        assert script.title == ""

    def test_token_expiry_edge_cases(self):
        """Test OAuth token expiry edge cases"""
        from processor.oauth_manager import OAuthToken
        from processor.config import utc_now

        # Token that expires immediately
        immediate_expire = OAuthToken(
            access_token="expire-now",
            expires_in=0,
            created_at=utc_now() - timedelta(seconds=1),
        )
        assert immediate_expire.is_expired

        # Token with very long expiry
        long_expire = OAuthToken(
            access_token="long-expire",
            expires_in=86400 * 365,  # 1 year
            created_at=utc_now(),
        )
        assert not long_expire.is_expired

    def test_publish_result_failure_cases(self):
        """Test PublishResult with failure scenarios"""
        from processor.publishing_orchestrator import PublishResult, Platform

        # Failure case
        failure = PublishResult(
            platform=Platform.YOUTUBE, success=False, error="Rate limit exceeded"
        )
        assert not failure.success
        assert failure.error is not None
        assert failure.post_id is None

    def test_platform_enum_completeness(self):
        """Test that all expected platforms are defined"""
        from processor.publishing_orchestrator import Platform

        # Verify key platforms exist
        platforms = list(Platform)
        assert len(platforms) >= 4  # At least YouTube, Instagram, TikTok, Twitter


# ============================================================================
# Configuration Extended Tests
# ============================================================================


class TestConfigurationExtended:
    """Extended configuration tests"""

    def test_settings_api_keys_default_empty(self):
        """Test that API keys default to empty strings"""
        from processor.config import get_settings

        settings = get_settings()
        # API keys should exist but may be empty in test environment
        assert hasattr(settings, "openai_api_key")
        assert hasattr(settings, "elevenlabs_api_key")

    def test_settings_database_config(self):
        """Test database configuration settings"""
        from processor.config import get_settings

        settings = get_settings()
        assert hasattr(settings, "database_host") or hasattr(settings, "postgres_host")
        # Check for redis_url instead of redis_host
        assert hasattr(settings, "redis_url") or hasattr(settings, "redis_host")

    def test_settings_kafka_config(self):
        """Test Kafka configuration settings"""
        from processor.config import get_settings

        settings = get_settings()
        assert hasattr(settings, "kafka_bootstrap_servers")

    def test_settings_logging_level(self):
        """Test logging configuration"""
        from processor.config import get_settings

        settings = get_settings()
        # Verify logging level is set
        assert hasattr(settings, "log_level") or hasattr(settings, "debug")


# ============================================================================
# Agent Communication Tests
# ============================================================================


class TestAgentCommunicationExtended:
    """Tests for agent communication patterns"""

    def test_message_bus_subscription(self):
        """Test message bus subscription mechanism"""
        from processor.ai_agents import AgentMessageBus

        bus = AgentMessageBus()
        received_messages = []

        def handler(message):
            received_messages.append(message)

        # Subscribe to a topic - check if bus has subscribe method
        assert bus is not None
        assert (
            hasattr(bus, "publish") or hasattr(bus, "subscribe") or hasattr(bus, "send")
        )

    def test_agent_decision_validation(self):
        """Test agent decision validation"""
        from processor.ai_agents import AgentDecision

        # Valid decision with all required fields
        decision = AgentDecision(
            decision_id="decision-001",
            agent_name="test_agent",
            decision_type="content_approval",  # Required field
            input_data={"content": "test"},
            reasoning="Based on analysis",
            action="approve",
            confidence=0.95,
        )

        assert decision.confidence >= 0.0
        assert decision.confidence <= 1.0
        assert decision.reasoning != ""

    def test_message_priority_ordering(self):
        """Test message priority ordering"""
        from processor.ai_agents import AgentMessage, MessageType

        messages = [
            AgentMessage(
                id="msg-1",
                sender="agent1",
                recipient="agent2",
                message_type=MessageType.TASK,
                payload={},
                priority=1,
            ),
            AgentMessage(
                id="msg-2",
                sender="agent1",
                recipient="agent2",
                message_type=MessageType.TASK,
                payload={},
                priority=10,
            ),
            AgentMessage(
                id="msg-3",
                sender="agent1",
                recipient="agent2",
                message_type=MessageType.TASK,
                payload={},
                priority=5,
            ),
        ]

        # Sort by priority (higher = more important)
        sorted_messages = sorted(messages, key=lambda m: m.priority, reverse=True)
        assert sorted_messages[0].id == "msg-2"
        assert sorted_messages[-1].id == "msg-1"


# ============================================================================
# Async Integration Tests (pytest-asyncio)
# ============================================================================


class TestAsyncVideoFactory:
    """Async tests for video factory module"""

    @pytest.mark.asyncio
    async def test_video_script_generator_async(self):
        """Test VideoScriptGenerator async methods"""
        from processor.video_factory import VideoScriptGenerator

        generator = VideoScriptGenerator()
        assert generator is not None
        # Verify async method exists
        assert hasattr(generator, "generate") or hasattr(generator, "generate_script")

    @pytest.mark.asyncio
    async def test_elevenlabs_client_async(self):
        """Test ElevenLabsClient async initialization"""
        from processor.video_factory import ElevenLabsClient

        # ElevenLabsClient requires api_key parameter
        client = ElevenLabsClient(api_key="test-api-key")
        assert client is not None
        # Actual method is generate_speech
        assert hasattr(client, "generate_speech")

    @pytest.mark.asyncio
    async def test_did_client_async(self):
        """Test DIDClient async initialization"""
        from processor.video_factory import DIDClient

        # DIDClient requires api_key parameter
        client = DIDClient(api_key="test-api-key")
        assert client is not None
        # Actual method is create_talk
        assert hasattr(client, "create_talk")


class TestAsyncTrendSources:
    """Async tests for trend sources module"""

    @pytest.mark.asyncio
    async def test_trend_aggregator_fetch_async(self):
        """Test TrendAggregator async fetch methods"""
        from processor.trend_sources import TrendAggregator

        aggregator = TrendAggregator()
        assert aggregator is not None
        assert hasattr(aggregator, "fetch_all_trends")

    @pytest.mark.asyncio
    async def test_google_trends_source_async(self):
        """Test GoogleTrendsSource async methods"""
        from processor.trend_sources import GoogleTrendsSource

        source = GoogleTrendsSource()
        assert source is not None
        assert hasattr(source, "fetch_trends") or hasattr(source, "get_trends")

    @pytest.mark.asyncio
    async def test_twitter_trends_source_async(self):
        """Test TwitterTrendsSource async methods"""
        from processor.trend_sources import TwitterTrendsSource

        source = TwitterTrendsSource()
        assert source is not None


class TestAsyncPublishing:
    """Async tests for publishing orchestrator"""

    @pytest.mark.asyncio
    async def test_publishing_orchestrator_async(self):
        """Test PublishingOrchestrator async methods"""
        from processor.publishing_orchestrator import PublishingOrchestrator

        orchestrator = PublishingOrchestrator()
        assert orchestrator is not None
        # Actual method is publish_now
        assert hasattr(orchestrator, "publish_now") or hasattr(orchestrator, "queue")

    @pytest.mark.asyncio
    async def test_rate_limiter_async(self):
        """Test RateLimiter async methods"""
        from processor.publishing_orchestrator import RateLimiter

        limiter = RateLimiter()
        assert limiter is not None
        # Actual method is acquire
        assert hasattr(limiter, "acquire") or hasattr(limiter, "tokens")


class TestAsyncOAuth:
    """Async tests for OAuth manager"""

    @pytest.mark.asyncio
    async def test_oauth_manager_async(self):
        """Test OAuthManager async methods"""
        from processor.oauth_manager import OAuthManager

        manager = OAuthManager()
        assert manager is not None
        # Actual method is get_authorization_url
        assert hasattr(manager, "get_authorization_url") or hasattr(
            manager, "providers"
        )

    @pytest.mark.asyncio
    async def test_token_storage_async(self):
        """Test token storage async operations"""
        from processor.oauth_manager import InMemoryTokenStorage

        storage = InMemoryTokenStorage()
        assert storage is not None
        assert hasattr(storage, "save_token")
        assert hasattr(storage, "get_token")


class TestAsyncAnalytics:
    """Async tests for analytics pipeline"""

    @pytest.mark.asyncio
    async def test_analytics_pipeline_async(self):
        """Test AnalyticsPipeline async methods"""
        from processor.analytics_pipeline import AnalyticsPipeline

        pipeline = AnalyticsPipeline()
        assert pipeline is not None
        assert hasattr(pipeline, "start") or hasattr(pipeline, "process_event")

    @pytest.mark.asyncio
    async def test_event_producer_async(self):
        """Test EventProducer async methods"""
        from processor.analytics_pipeline import EventProducer

        producer = EventProducer()
        assert producer is not None


# ============================================================================
# Mock External API Tests
# ============================================================================


class TestMockedExternalAPIs:
    """Tests with mocked external API calls"""

    def test_anthropic_api_mock(self):
        """Test with mocked Anthropic API"""
        from processor.config import get_settings
        from unittest.mock import patch

        with patch("processor.config.settings") as mock_settings:
            mock_settings.anthropic_api_key = "test-key"
            mock_settings.claude_model = "claude-3-5-sonnet"

            settings = get_settings()
            assert settings is not None

    def test_openai_api_mock(self):
        """Test with mocked OpenAI API"""
        from processor.config import get_settings
        from unittest.mock import patch

        with patch("processor.config.settings") as mock_settings:
            mock_settings.openai_api_key = "test-openai-key"
            mock_settings.embedding_model = "text-embedding-3-small"

            settings = get_settings()
            assert settings is not None

    def test_elevenlabs_api_mock(self):
        """Test with mocked ElevenLabs API"""
        from processor.video_factory import ElevenLabsClient

        client = ElevenLabsClient(api_key="test-api-key")
        assert client is not None
        assert hasattr(client, "generate_speech")

    def test_did_api_mock(self):
        """Test with mocked D-ID API"""
        from processor.video_factory import DIDClient

        client = DIDClient(api_key="test-api-key")
        assert client is not None
        assert hasattr(client, "create_talk")


# ============================================================================
# Edge Case and Boundary Tests
# ============================================================================


class TestEdgeCases:
    """Tests for edge cases and boundary conditions"""

    def test_empty_trend_list(self):
        """Test handling of empty trend list"""
        from processor.trend_sources import TrendAggregator

        aggregator = TrendAggregator()
        # Empty sources should not crash
        assert aggregator.sources is not None or hasattr(aggregator, "sources")

    def test_very_long_content(self):
        """Test handling of very long content"""
        from processor.video_factory import VideoScript

        long_body = "This is a test. " * 10000  # 160,000 characters
        script = VideoScript(
            title="Long Content Test",
            hook="Testing...",
            body=long_body,
            call_to_action="Subscribe!",
        )
        assert len(script.body) == len(long_body)

    def test_special_characters_in_content(self):
        """Test handling of special characters"""
        from processor.video_factory import VideoScript

        special_content = (
            "Test with mojis  and spcial haracters: <script>alert('xss')</script>"
        )
        script = VideoScript(
            title=special_content,
            hook=special_content,
            body=special_content,
            call_to_action=special_content,
        )
        assert script.title == special_content

    def test_unicode_content(self):
        """Test handling of unicode content"""
        from processor.trend_sources import TrendItem

        trend = TrendItem(
            id="unicode-test",
            name="  ",
            source="test",
            score=0.9,
            volume=1000,
            growth_rate=0.5,
        )
        assert "" in trend.name

    def test_negative_values(self):
        """Test handling of edge case numeric values"""
        from processor.trend_sources import TrendItem

        # Negative values should be allowed (might indicate decline)
        trend = TrendItem(
            id="negative-test",
            name="Declining Trend",
            source="test",
            score=0.1,
            volume=100,
            growth_rate=-0.5,  # Negative growth
        )
        assert trend.growth_rate == -0.5


# ============================================================================
# Integration Workflow Tests
# ============================================================================


class TestIntegrationWorkflows:
    """Tests for complete integration workflows"""

    def test_content_curation_workflow(self):
        """Test complete content curation workflow"""
        from processor.trend_sources import TrendItem
        from processor.video_factory import VideoScript
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        # Step 1: Trend detected
        trend = TrendItem(
            id="workflow-001",
            name="Trending Topic",
            source="google",
            score=0.95,
            volume=100000,
            growth_rate=0.5,
        )

        # Step 2: Script generated
        script = VideoScript(
            title=f"Breaking: {trend.name}",
            hook="You won't believe this...",
            body=f"Today we discuss {trend.name}",
            call_to_action="Subscribe!",
        )

        # Step 3: Event logged
        event = PipelineEvent(
            event_id="evt-workflow-001",
            event_type=EventType.CONTENT_CREATED,
            timestamp=utc_now(),
            source="workflow_test",
            data={"trend_id": trend.id, "script_title": script.title},
        )

        # Verify workflow completed
        assert trend.score > 0.9
        assert script.title.startswith("Breaking:")
        assert event.event_type == EventType.CONTENT_CREATED

    def test_multi_platform_scheduling(self):
        """Test multi-platform content scheduling"""
        from processor.publishing_orchestrator import TimingOptimizer, Platform

        optimizer = TimingOptimizer()
        content = {"title": "Test Video", "category": "tech"}

        # Get optimal times for multiple platforms
        platforms = [Platform.YOUTUBE, Platform.TIKTOK, Platform.TWITTER]
        schedules = {}

        for platform in platforms:
            times = optimizer.get_optimal_times(platform, content)
            schedules[platform] = times

        # Verify all platforms have schedules
        assert len(schedules) == 3
        for platform, times in schedules.items():
            assert times is not None

    def test_analytics_aggregation(self):
        """Test analytics event aggregation"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        events = []
        platforms = ["youtube", "tiktok", "instagram"]

        for i, platform in enumerate(platforms):
            events.append(
                PipelineEvent(
                    event_id=f"agg-{i}",
                    event_type=EventType.PUBLISH_SUCCESS,
                    timestamp=utc_now(),
                    source="test",
                    data={"platform": platform, "views": (i + 1) * 1000},
                )
            )

        # Aggregate views
        total_views = sum(e.data.get("views", 0) for e in events)
        assert total_views == 6000  # 1000 + 2000 + 3000


# ============================================================================
# Data Validation Tests
# ============================================================================


class TestDataValidation:
    """Tests for data validation"""

    def test_trend_item_required_fields(self):
        """Test TrendItem validates required fields"""
        from processor.trend_sources import TrendItem

        # Should work with all required fields
        trend = TrendItem(
            id="valid-001",
            name="Valid Trend",
            source="google",
            score=0.8,
            volume=1000,
            growth_rate=0.2,
        )
        assert trend.id == "valid-001"

    def test_video_script_required_fields(self):
        """Test VideoScript validates required fields"""
        from processor.video_factory import VideoScript

        # Should work with all required fields
        script = VideoScript(
            title="Test Title",
            hook="Test Hook",
            body="Test Body",
            call_to_action="Test CTA",
        )
        assert script.title == "Test Title"

    def test_pipeline_event_required_fields(self):
        """Test PipelineEvent validates required fields"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        event = PipelineEvent(
            event_id="valid-evt",
            event_type=EventType.CONTENT_CREATED,
            timestamp=utc_now(),
            source="test",
            data={},
        )
        assert event.event_id == "valid-evt"

    def test_oauth_token_required_fields(self):
        """Test OAuthToken validates required fields"""
        from processor.oauth_manager import OAuthToken

        token = OAuthToken(access_token="test-token", expires_in=3600)
        assert token.access_token == "test-token"


# ============================================================================
# Concurrency Tests
# ============================================================================


class TestConcurrency:
    """Tests for concurrent operations"""

    @pytest.mark.asyncio
    async def test_concurrent_trend_creation(self):
        """Test concurrent TrendItem creation"""
        from processor.trend_sources import TrendItem

        async def create_trend(i):
            return TrendItem(
                id=f"concurrent-{i}",
                name=f"Trend {i}",
                source="test",
                score=0.5,
                volume=i * 100,
                growth_rate=0.1,
            )

        # Create 100 trends concurrently
        tasks = [create_trend(i) for i in range(100)]
        trends = await asyncio.gather(*tasks)

        assert len(trends) == 100
        assert all(t.id.startswith("concurrent-") for t in trends)

    @pytest.mark.asyncio
    async def test_concurrent_event_creation(self):
        """Test concurrent PipelineEvent creation"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now

        async def create_event(i):
            return PipelineEvent(
                event_id=f"concurrent-evt-{i}",
                event_type=EventType.CONTENT_CREATED,
                timestamp=utc_now(),
                source="test",
                data={"index": i},
            )

        # Create 100 events concurrently
        tasks = [create_event(i) for i in range(100)]
        events = await asyncio.gather(*tasks)

        assert len(events) == 100


# ============================================================================
# Serialization Tests
# ============================================================================


class TestSerialization:
    """Tests for serialization/deserialization"""

    def test_pipeline_event_json_roundtrip(self):
        """Test PipelineEvent JSON serialization roundtrip"""
        from processor.analytics_pipeline import PipelineEvent, EventType
        from processor.config import utc_now
        import json

        event = PipelineEvent(
            event_id="serial-001",
            event_type=EventType.VIDEO_PRODUCED,
            timestamp=utc_now(),
            source="test",
            data={"key": "value", "nested": {"a": 1}},
        )

        # Serialize to JSON
        json_str = event.to_json()
        assert isinstance(json_str, str)

        # Parse JSON
        parsed = json.loads(json_str)
        assert parsed["event_id"] == "serial-001"
        assert parsed["data"]["nested"]["a"] == 1

    def test_oauth_token_dict_conversion(self):
        """Test OAuthToken dict conversion"""
        from processor.oauth_manager import OAuthToken
        from processor.config import utc_now

        token = OAuthToken(
            access_token="test-token",
            token_type="Bearer",
            expires_in=3600,
            refresh_token="refresh-123",
            platform="youtube",
            created_at=utc_now(),
        )

        # Convert to dict
        token_dict = token.to_dict()
        assert token_dict["access_token"] == "test-token"
        assert token_dict["platform"] == "youtube"

    def test_trend_aggregation_serialization(self):
        """Test TrendAggregation serialization"""
        from processor.trend_sources import TrendAggregation

        aggregation = TrendAggregation(
            name="Test Trend",
            normalized_name="test_trend",
            sources=["google", "twitter"],
            combined_score=0.85,
            total_volume=50000,
            avg_growth_rate=0.25,
        )

        # Verify data access
        assert aggregation.name == "Test Trend"
        assert len(aggregation.sources) == 2
